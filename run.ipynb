{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['links.csv', 'movies.csv', 'ratings.csv', 'README.txt', 'tags.csv']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "os.listdir('./data/ml-latest-small/ml-latest-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zaq7tRPvhZXT",
        "outputId": "6dddcf91-df3a-4af8-b75a-a0203b1bf5ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>847434962</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1106635946</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1510577970</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1305696483</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp             title   \n",
              "0       1        1     4.0   964982703  Toy Story (1995)  \\\n",
              "1       5        1     4.0   847434962  Toy Story (1995)   \n",
              "2       7        1     4.5  1106635946  Toy Story (1995)   \n",
              "3      15        1     2.5  1510577970  Toy Story (1995)   \n",
              "4      17        1     4.5  1305696483  Toy Story (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "4  Adventure|Animation|Children|Comedy|Fantasy  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies = pd.read_csv('./data/ml-latest-small/ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('./data/ml-latest-small/ml-latest-small/ratings.csv')\n",
        "df = pd.merge(ratings, movies, on='movieId', how='inner')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlWbMjEgggB6",
        "outputId": "f9ad0aba-48d3-43cf-cba9-ed85c8f010e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100836 entries, 0 to 100835\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   userId     100836 non-null  int64  \n",
            " 1   movieId    100836 non-null  int64  \n",
            " 2   rating     100836 non-null  float64\n",
            " 3   timestamp  100836 non-null  int64  \n",
            " 4   title      100836 non-null  object \n",
            " 5   genres     100836 non-null  object \n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 4.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LRwB5FMHk2kW"
      },
      "outputs": [],
      "source": [
        "df[['userId', 'movieId']] = df[['userId', 'movieId']].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M4ypT2DhqqH",
        "outputId": "9f626799-3e7a-4b34-ea20-7494314da11b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9724, 610)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_movies = len(df['movieId'].unique())\n",
        "n_users = len(df['userId'].unique())\n",
        "n_movies, n_users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NjRwoWlN5_a"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nGcoWXusN5IG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def data_process(data):\n",
        "    # data = pd.read_csv(data_path)\n",
        "\n",
        "    # Remove all rows where rating == 3\n",
        "    data = data.drop(data[data['rating'] == 3].index)\n",
        "    data['rating'] = data['rating'].apply(lambda x: 1 if x > 3 else 0)\n",
        "    data = data.sort_values(by='timestamp', ascending=True)\n",
        "    train,test = train_test_split(data,test_size= 0.2 )\n",
        "    return train, test, data\n",
        "\n",
        "\n",
        "def get_user_feature(data):\n",
        "    # get user history and mean user rating\n",
        "    data_group = df[df['rating'] == 1]\n",
        "    data_group = data_group[['userId', 'movieId']].groupby('userId').agg(list).reset_index()\n",
        "    data_group['user_hist'] = data_group['movieId'].apply(lambda x: '|'.join([str(i) for i in x]))\n",
        "    data = pd.merge(data_group.drop('movieId', axis=1), data, on='userId')\n",
        "    data_group = data[['userId', 'rating']].groupby('userId').agg('mean').reset_index()\n",
        "    data_group.rename(columns={'rating': 'user_mean_rating'}, inplace=True)\n",
        "    data = pd.merge(data_group, data, on='userId')\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_item_feature(data):\n",
        "    # get mean item rating\n",
        "    data_group = data[['movieId', 'rating']].groupby('movieId').agg('mean').reset_index()\n",
        "    data_group.rename(columns={'rating': 'item_mean_rating'}, inplace=True)\n",
        "    data = pd.merge(data_group, data, on='movieId')\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_var_feature(data, col):\n",
        "    key2index = {}\n",
        "\n",
        "    def split(x):\n",
        "        key_ans = x.split('|')\n",
        "        for key in key_ans:\n",
        "            if key not in key2index:\n",
        "                # Notice : input value 0 is a special \"padding\",\\\n",
        "                # so we do not use 0 to encode valid feature for sequence input\n",
        "                key2index[key] = len(key2index) + 1\n",
        "        return torch.Tensor(list(map(lambda x: key2index[x], key_ans)))\n",
        "\n",
        "    var_feature = list(map(split, data[col].values))\n",
        "    print(var_feature)\n",
        "    var_feature_length = np.array(list(map(len, var_feature)))\n",
        "    max_len = max(var_feature_length)\n",
        "    # var_feature = torch.nn.utils.rnn.pad_sequence(var_feature, )\n",
        "    var_feature = pad_sequences(var_feature, maxlen=max_len, padding='post', )\n",
        "    return key2index, var_feature, max_len\n",
        "\n",
        "\n",
        "def get_test_var_feature(data, col, key2index, max_len):\n",
        "    print(\"user_hist_list: \\n\")\n",
        "\n",
        "    def split(x):\n",
        "        key_ans = x.split('|')\n",
        "        for key in key_ans:\n",
        "            if key not in key2index:\n",
        "                # Notice : input value 0 is a special \"padding\",\n",
        "                # so we do not use 0 to encode valid feature for sequence input\n",
        "                key2index[key] = len(key2index) + 1\n",
        "        return list(map(lambda x: key2index[x], key_ans))\n",
        "\n",
        "    test_hist = list(map(split, data[col].values))\n",
        "    test_hist = pad_sequences(test_hist, maxlen=max_len, padding='post')\n",
        "    return test_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nK9JYAz-ODU3"
      },
      "outputs": [],
      "source": [
        "train, test, data = data_process(df)\n",
        "\n",
        "train = get_user_feature(train)\n",
        "train = get_item_feature(train)\n",
        "\n",
        "test = get_user_feature(test)\n",
        "test = get_item_feature(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "K4KmeHJ6XMRF",
        "outputId": "4ec434ad-6d28-4a04-ba9a-8dc45802f898"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>item_mean_rating</th>\n",
              "      <th>userId</th>\n",
              "      <th>user_mean_rating</th>\n",
              "      <th>user_hist</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>1</td>\n",
              "      <td>0.970238</td>\n",
              "      <td>3176</td>\n",
              "      <td>1</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>103</td>\n",
              "      <td>0.931507</td>\n",
              "      <td>64114|91671|132046</td>\n",
              "      <td>1</td>\n",
              "      <td>1431954238</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>121</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>44|272</td>\n",
              "      <td>1</td>\n",
              "      <td>847656180</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>132</td>\n",
              "      <td>0.594595</td>\n",
              "      <td>4643|3264</td>\n",
              "      <td>0</td>\n",
              "      <td>1157921785</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>135</td>\n",
              "      <td>0.810651</td>\n",
              "      <td>153|65|165|1917|1544|1372|1722|3248|4621|1694|...</td>\n",
              "      <td>1</td>\n",
              "      <td>1009691859</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movieId  item_mean_rating userId  user_mean_rating   \n",
              "0       1          0.858586      1          0.970238  \\\n",
              "1       1          0.858586    103          0.931507   \n",
              "2       1          0.858586    121          0.809524   \n",
              "3       1          0.858586    132          0.594595   \n",
              "4       1          0.858586    135          0.810651   \n",
              "\n",
              "                                           user_hist  rating   timestamp   \n",
              "0                                               3176       1   964982703  \\\n",
              "1                                 64114|91671|132046       1  1431954238   \n",
              "2                                             44|272       1   847656180   \n",
              "3                                          4643|3264       0  1157921785   \n",
              "4  153|65|165|1917|1544|1372|1722|3248|4621|1694|...       1  1009691859   \n",
              "\n",
              "              title                                       genres  \n",
              "0  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "2  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "3  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "4  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  "
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rgW80NPYDo8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "sparse_features = ['userId', 'movieId']  # , 'gender', 'age', 'occupation'\n",
        "dense_features = ['user_mean_rating', 'item_mean_rating']\n",
        "target = ['rating']\n",
        "\n",
        "user_sparse_features, user_dense_features = ['userId'], ['user_mean_rating']   # , 'gender', 'age', 'occupation'\n",
        "item_sparse_features, item_dense_features = ['movieId', ], ['item_mean_rating']\n",
        "\n",
        "# 1.Label Encoding for sparse features, and process sequence features\n",
        "for feat in sparse_features:\n",
        "    lbe = LabelEncoder()\n",
        "    lbe.fit(data[feat])\n",
        "    train[feat] = lbe.transform(train[feat])\n",
        "    test[feat] = lbe.transform(test[feat])\n",
        "\n",
        "mms = MinMaxScaler(feature_range=(0, 1))  # does this make sense? Mean ratings are already [0,1]\n",
        "mms.fit(train[dense_features])\n",
        "mms.fit(test[dense_features])  # I don't think we should be fitting to test set\n",
        "train[dense_features] = mms.transform(train[dense_features])\n",
        "test[dense_features] = mms.transform(test[dense_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "4wuQTyWNZJGt",
        "outputId": "f7667a48-467f-490f-dbd6-ade4ecff7964"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>item_mean_rating</th>\n",
              "      <th>userId</th>\n",
              "      <th>user_mean_rating</th>\n",
              "      <th>user_hist</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>1</td>\n",
              "      <td>0.970238</td>\n",
              "      <td>3176</td>\n",
              "      <td>1</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>103</td>\n",
              "      <td>0.931507</td>\n",
              "      <td>64114|91671|132046</td>\n",
              "      <td>1</td>\n",
              "      <td>1431954238</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>121</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>44|272</td>\n",
              "      <td>1</td>\n",
              "      <td>847656180</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>132</td>\n",
              "      <td>0.594595</td>\n",
              "      <td>4643|3264</td>\n",
              "      <td>0</td>\n",
              "      <td>1157921785</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.858586</td>\n",
              "      <td>135</td>\n",
              "      <td>0.810651</td>\n",
              "      <td>153|65|165|1917|1544|1372|1722|3248|4621|1694|...</td>\n",
              "      <td>1</td>\n",
              "      <td>1009691859</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  movieId  item_mean_rating userId  user_mean_rating   \n",
              "0       1          0.858586      1          0.970238  \\\n",
              "1       1          0.858586    103          0.931507   \n",
              "2       1          0.858586    121          0.809524   \n",
              "3       1          0.858586    132          0.594595   \n",
              "4       1          0.858586    135          0.810651   \n",
              "\n",
              "                                           user_hist  rating   timestamp   \n",
              "0                                               3176       1   964982703  \\\n",
              "1                                 64114|91671|132046       1  1431954238   \n",
              "2                                             44|272       1   847656180   \n",
              "3                                          4643|3264       0  1157921785   \n",
              "4  153|65|165|1917|1544|1372|1722|3248|4621|1694|...       1  1009691859   \n",
              "\n",
              "              title                                       genres  \n",
              "0  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "2  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "3  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "4  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZWeduj5aeyq"
      },
      "outputs": [],
      "source": [
        "# 2.preprocess the sequence feature\n",
        "\n",
        "genres_key2index, train_genres_list, genres_maxlen = get_var_feature(train, 'genres')\n",
        "user_key2index, train_user_hist, user_maxlen = get_var_feature(train, 'user_hist')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axNiA4PXy1Z5"
      },
      "outputs": [],
      "source": [
        "# user_sparse_features, user_dense_features = ['userId'], ['user_mean_rating']   # , 'gender', 'age', 'occupation'\n",
        "# item_sparse_features, item_dense_features = ['movieId', ], ['item_mean_rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHKCdTrwm06L"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(feature_subset, embedding_dim=32, init_std=0.0001, linear=False, sparse=False, device='cpu'):\n",
        "\n",
        "    feature_columns = feature_subset.columns\n",
        "    embedding_dict = nn.ModuleDict({feat_name: nn.Embedding(feature_subset[feat_name].nunique(),\n",
        "                                                                      embedding_dim if not linear else 1)\n",
        "                                    for feat_name in feature_columns})\n",
        "\n",
        "    for tensor in embedding_dict.values():\n",
        "        nn.init.normal_(tensor.weight, mean=0, std=init_std)\n",
        "\n",
        "    return embedding_dict.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB3o47nt0cVf"
      },
      "outputs": [],
      "source": [
        "user_embedding_dict = create_embedding_matrix(df[['userId']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67DT_qLu1VSG",
        "outputId": "df70e1c7-f458-4564-8add-cbd7e7049ee0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModuleDict(\n",
              "  (userId): Embedding(610, 32)\n",
              ")"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_embedding_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEoutHYY4o0d"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FfCp8kEwaNw7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8-2ccBP8UWX1"
      },
      "outputs": [],
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "        # encode the string idx for users and movies\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.item_encoder = LabelEncoder()\n",
        "        self.df['userId'] = self.user_encoder.fit_transform(self.df['userId'])\n",
        "        self.df['movieId'] = self.item_encoder.fit_transform(self.df['movieId'])\n",
        "        self.N_USERS = len(self.user_encoder.classes_)\n",
        "        self.N_MOVIES = len(self.item_encoder.classes_)\n",
        "\n",
        "        # Convert data to PyTorch tensors\n",
        "        self.users = torch.tensor(self.df['userId'].values)\n",
        "        self.movies = torch.tensor(self.df['movieId'].values)\n",
        "        self.ratings = torch.tensor(self.df['rating'].values)\n",
        "\n",
        "        # binarize values, if rating is over 3.5 stars = 1, otherwise = 0\n",
        "        # self.ratings = torch.where(self.ratings > 3.5, 1.0, 0.0)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.movies[idx], self.ratings[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0,  5, 15]), tensor([0, 0, 0]), tensor([1, 1, 1]))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = MovieLensDataset(train)\n",
        "ds[:3] \n",
        "# (tensor([ 0,  5, 15]), tensor([0, 0, 0]), tensor([1, 1, 1]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoVeq1u54mSr"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOpys4MbAUvK"
      },
      "outputs": [],
      "source": [
        "class StringLookup(nn.Module):\n",
        "    def __init__(self, vocabulary, num_oov_indices=1, mask_token=None):\n",
        "        super().__init__()\n",
        "\n",
        "        '''\n",
        "         initializes the lookup table with an embedding matrix, \n",
        "         where each word in the vocabulary is assigned a unique index. \n",
        "         We also fill the weights with 1s for the tokens in the vocabulary, \n",
        "         so they will be \"looked up\" properly during forward propagation. \n",
        "         The OOV indices are initialized to 0.\n",
        "        '''\n",
        "\n",
        "        self.num_oov_indices = num_oov_indices\n",
        "        self.mask_token = mask_token\n",
        "        word_2_idx = {w: i for i, w in enumerate(vocabulary)}\n",
        "\n",
        "        # Create the vocabulary lookup table\n",
        "        self.lookup_table = nn.Embedding(len(vocabulary) + num_oov_indices, 1, padding_idx=None)\n",
        "        self.lookup_table.weight.data.fill_(0)\n",
        "        for i, token in enumerate(vocabulary):\n",
        "            self.lookup_table.weight.data[i] = i + num_oov_indices\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        '''\n",
        "        performs the actual lookup operation. \n",
        "        We first apply the mask if the mask_token argument is provided. \n",
        "        Then we add the number of OOV indices to the input values so \n",
        "        that they correspond to the correct index in the embedding matrix. \n",
        "        Finally, we lookup the indices in the embedding matrix and return the outputs.\n",
        "        '''\n",
        "\n",
        "        if self.mask_token is not None:\n",
        "            mask = inputs != self.mask_token\n",
        "            inputs = inputs.masked_fill(~mask, 0)\n",
        "\n",
        "        # Add the number of OOV indices to the input values\n",
        "        inputs += len(self.lookup_table.weight)\n",
        "\n",
        "        # Lookup the indices in the vocabulary table\n",
        "        outputs = self.lookup_table(inputs)\n",
        "\n",
        "        return outputs.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "OE83mpnuf3ez"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SimpleTwoTower(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_items, n_users, embedding_size, ln=None):\n",
        "        super(SimpleTwoTower, self).__init__()\n",
        "\n",
        "\n",
        "        # self.userid_embedding = tf.keras.Sequential([\n",
        "        #     tf.keras.layers.StringLookup(\n",
        "        #         vocabulary=unique_user_ids, mask_token=None),\n",
        "        #     tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "        # ])\n",
        "\n",
        "        # self.user_id_embedding = nn.Sequential([\n",
        "            \n",
        "        #     nn.Embedding(len(unique_user_ids), 5, padding_idx=0),\n",
        "        #     nn.Embedding(num_embeddings=(n_users + 1), embedding_dim=embedding_size)\n",
        "        # ])\n",
        "\n",
        "        # self.timestamp_embedding = tf.keras.Sequential([\n",
        "        #     tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "        #     tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "        # ])\n",
        "        # self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "        #     axis=None\n",
        "        # )\n",
        "\n",
        "        # self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "        # --------------------------------------------------------------\n",
        "        \n",
        "        # self.ln = ln\n",
        "        self.item_emb = nn.Embedding(num_embeddings=n_items, embedding_dim=embedding_size)  # self.ln[0]\n",
        "        # We add +1 additional embedding to account for unknown tokens.\n",
        "        self.user_emb = nn.Embedding(num_embeddings=n_users + 1, embedding_dim=embedding_size)\n",
        "       \n",
        "        \n",
        "        self.item_layers = [] #nn.ModuleList()\n",
        "        self.user_layers = [] #nn.ModuleList()\n",
        "        \n",
        "        # for i, n in enumerate(ln[0:-1]):\n",
        "        #     m = int(ln[i+1])\n",
        "        self.item_layers.append(nn.Linear(embedding_size, embedding_size, bias=True))  # n, m\n",
        "        self.item_layers.append(nn.ReLU())\n",
        "        \n",
        "        self.user_layers.append(nn.Linear(embedding_size, embedding_size, bias=True))\n",
        "        self.user_layers.append(nn.ReLU())   # is this ReLU needed???\n",
        "            \n",
        "            \n",
        "        self.item_layers = nn.Sequential(*self.item_layers)\n",
        "        self.user_layers = nn.Sequential(*self.user_layers)\n",
        "        \n",
        "        self.dot = torch.matmul\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, users, items):\n",
        "\n",
        "        # Take the input dictionary, pass it through each input layer,\n",
        "        # and concatenate the result\n",
        "        '''\n",
        "        return tf.concat([\n",
        "            self.user_embedding(inputs[\"user_id\"]),\n",
        "            self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "            tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "        ], axis=1)\n",
        "        '''\n",
        "\n",
        "        \n",
        "        item_emb = self.item_emb(items) # [B, embed_size]\n",
        "        user_emb = self.user_emb(users) # [B, embed_size]\n",
        "        print(user_emb.shape, item_emb.shape)\n",
        "        \n",
        "        item_emb = self.item_layers(item_emb) # [B, embed_size]\n",
        "        user_emb = self.user_layers(user_emb) # [B, embed_size]\n",
        "\n",
        "        print(user_emb.shape, item_emb.shape)\n",
        "        dp = self.dot(user_emb, item_emb.T) # [B, B]\n",
        "        print(dp)\n",
        "        dp = dp.sum(dim=1).squeeze() # [B]\n",
        "\n",
        "        return self.sigmoid(dp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "tt = SimpleTwoTower(n_items=len(ds.item_encoder.classes_),\n",
        "                    n_users=len(ds.user_encoder.classes_),\n",
        "                    embedding_size=8)\n",
        "\n",
        "train_dataloader = DataLoader(ds, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([171, 140, 316,  11]),\n",
              " tensor([2831, 4654, 6150, 5125]),\n",
              " tensor([1, 1, 0, 1])]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = next(iter(train_dataloader))\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 8]) torch.Size([4, 8])\n",
            "torch.Size([4, 8]) torch.Size([4, 8])\n",
            "tensor([[0.0109, 0.0000, 0.0000, 0.0492],\n",
            "        [0.0536, 0.0486, 0.0355, 0.0228],\n",
            "        [0.2337, 0.0481, 0.1612, 0.6567],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000]], grad_fn=<MmBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0.5150, 0.5400, 0.7502, 0.5000], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users, items, ratings = sample\n",
        "tt(users, items)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5C4fhwh4i2S"
      },
      "source": [
        "### Define Training / Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJGRAGHfj26g"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "# import horovod.torch as hvd\n",
        "# from sparkdl import HorovodRunner\n",
        "\n",
        "\n",
        "def save_checkpoint(model, epoch):\n",
        "    save_path = os.path.join(SAVE_MODEL_DIR, f\"Epoch{str(epoch)}_checkpoint.pt\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "def train_one_epoch(model, criterion, optimizer, scheduler, \n",
        "                    train_dataloader, steps_per_epoch, epoch, \n",
        "                    device, batch_size):\n",
        "\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # statistics\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over the data for one epoch.\n",
        "    for step in tqdm(range(steps_per_epoch)):\n",
        "\n",
        "        users, movies, ratings = next(iter(train_dataloader))\n",
        "\n",
        "\n",
        "        # Track history in training\n",
        "        with torch.set_grad_enabled(True):\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            logits = model(users, movies)\n",
        "            \n",
        "            preds = torch.round(logits)\n",
        "            loss = criterion(logits, ratings)\n",
        "\n",
        "            # backward + optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # statistics\n",
        "    running_loss += loss.item() * len(ratings)\n",
        "    running_corrects += torch.sum(preds == ratings)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    save_checkpoint(model, epoch)\n",
        "\n",
        "    epoch_loss = running_loss / (steps_per_epoch * batch_size)\n",
        "    epoch_acc = running_corrects.double() / (steps_per_epoch * batch_size)\n",
        "\n",
        "    print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, val_dataloader, validation_steps, device, batch_size,\n",
        "             metric_agg_fn=None):\n",
        "    model.eval()  # Set model to evaluate mode\n",
        "\n",
        "    # statistics\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over all the validation data.\n",
        "    for step in tqdm(range(validation_steps)):\n",
        "\n",
        "        users, movies, ratings = next(iter(val_dataloader))\n",
        "\n",
        "\n",
        "\n",
        "        # Do not track history in evaluation to save memory\n",
        "        with torch.set_grad_enabled(False):\n",
        "            # forward\n",
        "            outputs = model(users, movies)\n",
        "            preds = torch.round(outputs)\n",
        "            loss = criterion(outputs, ratings)\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == ratings.data)\n",
        "\n",
        "    # The losses are averaged across observations for each minibatch.\n",
        "    epoch_loss = running_loss / validation_steps\n",
        "    epoch_acc = running_corrects.double() / (validation_steps * batch_size)\n",
        "\n",
        "    # metric_agg_fn is used in the distributed training to aggregate the metrics on all workers\n",
        "    if metric_agg_fn is not None:\n",
        "        epoch_loss = metric_agg_fn(epoch_loss, 'avg_loss')\n",
        "        epoch_acc = metric_agg_fn(epoch_acc, 'avg_acc')\n",
        "\n",
        "    print('Validation Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duRhIr7j7M4L"
      },
      "source": [
        "### Run "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT8BR_helhcr"
      },
      "outputs": [],
      "source": [
        "# Set h-params\n",
        "\n",
        "LR = 1e-3\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    #     torch.cuda.set_device(hvd.local_rank())\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "STEP_SIZE = 20\n",
        "GAMMA = 0.1\n",
        "\n",
        "SAVE_MODEL_DIR = '/content/sample_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "idn1yN5-labZ",
        "outputId": "1f0f84a8-87d0-4d7c-ffe9-427d4a3537f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-70-853e075b8fd6>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df['movieId'] = self.df['movieId'].map(self.movie_id_map)\n",
            "<ipython-input-70-853e075b8fd6>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df['userId'] = self.df['userId'].map(self.user_id_map)\n",
            "<ipython-input-70-853e075b8fd6>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df['movieId'] = self.df['movieId'].map(self.movie_id_map)\n",
            "<ipython-input-70-853e075b8fd6>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.df['userId'] = self.df['userId'].map(self.user_id_map)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5042/5042 [03:03<00:00, 27.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0002 Acc: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1261/1261 [00:03<00:00, 334.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9272 Acc: 0.3861\n",
            "Epoch 2/100\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5042/5042 [02:59<00:00, 28.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0001 Acc: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1261/1261 [00:02<00:00, 478.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9274 Acc: 0.3859\n",
            "Epoch 3/100\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 413/5042 [00:15<02:58, 25.96it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-9c01108ae856>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# train_dataloader_iter, val_dataloader_iter = load_train_val_iterators()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     train_loss, train_acc = train_one_epoch(model, criterion, optimizer, exp_lr_scheduler, \n\u001b[0m\u001b[1;32m     38\u001b[0m                                             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                                             device, batch_size=BATCH_SIZE)\n",
            "\u001b[0;32m<ipython-input-93-1bb85ac83295>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, scheduler, train_dataloader, steps_per_epoch, epoch, device, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mhas_sparse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             sgd(params_with_grad,\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    223\u001b[0m          \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "#   hvd.init()  # Initialize Horovod.\n",
        "\n",
        "\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=0, stratify=df[['rating']])\n",
        "\n",
        "train_ds = MovieLensDataset(train_df)\n",
        "val_ds = MovieLensDataset(val_df)\n",
        "\n",
        "train_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model = SimpleTwoTower(n_items=train_ds.N_USERS, n_users=train_ds.N_MOVIES, embedding_size=64)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = LR, momentum=0.9) \n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "\n",
        "steps_per_epoch = len(train_dataloader)\n",
        "\n",
        "validation_steps = max(1, len(val_dataloader))\n",
        "\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print('Epoch {}/{}'.format(epoch + 1, NUM_EPOCHS))\n",
        "    print('-' * 10)\n",
        "\n",
        "\n",
        "    # train_dataloader_iter, val_dataloader_iter = load_train_val_iterators()\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(model, criterion, optimizer, exp_lr_scheduler, \n",
        "                                            train_dataloader, steps_per_epoch, epoch, \n",
        "                                            device, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    val_loss, val_acc = evaluate(model, criterion, \n",
        "                                 val_dataloader, validation_steps, \n",
        "                                 device, metric_agg_fn=None, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5O40XRPrFIS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
